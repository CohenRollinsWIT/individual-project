{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b53edbf-44a1-437c-9757-cf6f5d955b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LOGISTIC REGRESSION RESULTS ===\n",
      "Accuracy: 0.8481012658227848\n",
      "Precision: 0.9361702127659575\n",
      "Recall: 0.8301886792452831\n",
      "F1 Score: 0.88\n",
      "\n",
      "Confusion Matrix:\n",
      " [[23  3]\n",
      " [ 9 44]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.88      0.79        26\n",
      "           1       0.94      0.83      0.88        53\n",
      "\n",
      "    accuracy                           0.85        79\n",
      "   macro avg       0.83      0.86      0.84        79\n",
      "weighted avg       0.86      0.85      0.85        79\n",
      "\n",
      "\n",
      "=== RANDOM FOREST RESULTS ===\n",
      "Accuracy: 0.8734177215189873\n",
      "Precision: 0.9574468085106383\n",
      "Recall: 0.8490566037735849\n",
      "F1 Score: 0.9\n",
      "\n",
      "Confusion Matrix:\n",
      " [[24  2]\n",
      " [ 8 45]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.92      0.83        26\n",
      "           1       0.96      0.85      0.90        53\n",
      "\n",
      "    accuracy                           0.87        79\n",
      "   macro avg       0.85      0.89      0.86        79\n",
      "weighted avg       0.89      0.87      0.88        79\n",
      "\n",
      "\n",
      "=== TOP 15 IMPORTANT FEATURES ===\n",
      "       feature  importance\n",
      "14          G2    0.352732\n",
      "13          G1    0.216632\n",
      "5     failures    0.046290\n",
      "12    absences    0.039394\n",
      "8        goout    0.025591\n",
      "0          age    0.024273\n",
      "10        Walc    0.019071\n",
      "11      health    0.017613\n",
      "2         Fedu    0.016306\n",
      "1         Medu    0.015490\n",
      "3   traveltime    0.015033\n",
      "7     freetime    0.014484\n",
      "6       famrel    0.013215\n",
      "9         Dalc    0.012161\n",
      "4    studytime    0.011558\n",
      "\n",
      "All figures saved in the /graph folder.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df = pd.read_csv(\"../data/student-mat.csv\", sep=\";\")# MAKE SURE FILE IS IN /data FOLDER\n",
    "\n",
    "\n",
    "# Create Pass/Fail target column\n",
    "df[\"pass_fail\"] = df[\"G3\"].apply(lambda x: 1 if x >= 10 else 0)\n",
    "\n",
    "# Identify categorical variables\n",
    "categorical = df.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "# One-hot encode categorical columns\n",
    "df_encoded = pd.get_dummies(df, columns=categorical, drop_first=True)\n",
    "\n",
    "# Drop original grade columns G1 and G2 (optional but common)\n",
    "X = df_encoded.drop([\"G3\", \"pass_fail\"], axis=1)\n",
    "y = df_encoded[\"pass_fail\"]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=200)\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_lr = log_reg.predict(X_test_scaled)\n",
    "\n",
    "lr_accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "lr_precision = precision_score(y_test, y_pred_lr)\n",
    "lr_recall = recall_score(y_test, y_pred_lr)\n",
    "lr_f1 = f1_score(y_test, y_pred_lr)\n",
    "lr_cm = confusion_matrix(y_test, y_pred_lr)\n",
    "\n",
    "print(\"=== LOGISTIC REGRESSION RESULTS ===\")\n",
    "print(\"Accuracy:\", lr_accuracy)\n",
    "print(\"Precision:\", lr_precision)\n",
    "print(\"Recall:\", lr_recall)\n",
    "print(\"F1 Score:\", lr_f1)\n",
    "print(\"\\nConfusion Matrix:\\n\", lr_cm)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_lr))\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=300, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "rf_precision = precision_score(y_test, y_pred_rf)\n",
    "rf_recall = recall_score(y_test, y_pred_rf)\n",
    "rf_f1 = f1_score(y_test, y_pred_rf)\n",
    "rf_cm = confusion_matrix(y_test, y_pred_rf)\n",
    "\n",
    "print(\"\\n=== RANDOM FOREST RESULTS ===\")\n",
    "print(\"Accuracy:\", rf_accuracy)\n",
    "print(\"Precision:\", rf_precision)\n",
    "print(\"Recall:\", rf_recall)\n",
    "print(\"F1 Score:\", rf_f1)\n",
    "print(\"\\nConfusion Matrix:\\n\", rf_cm)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_rf))\n",
    "\n",
    "\n",
    "importances = pd.DataFrame({\n",
    "    \"feature\": X.columns,\n",
    "    \"importance\": rf.feature_importances_\n",
    "}).sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "print(\"\\n=== TOP 15 IMPORTANT FEATURES ===\")\n",
    "print(importances.head(15))\n",
    "\n",
    "\n",
    "\n",
    "# Grade Distribution\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(df[\"G3\"], kde=True)\n",
    "plt.title(\"Final Grade Distribution\")\n",
    "plt.xlabel(\"G3 (Final Grade)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.savefig(\"../graph/grade_dist.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Heatmap\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(df_encoded.corr(), cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.savefig(\"../graph/heatmap.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Feature Importance Plot\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(importances[\"feature\"][:15], importances[\"importance\"][:15])\n",
    "plt.title(\"Top 15 Feature Importances â€“ Random Forest\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.savefig(\"../graph/feature_importance.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Confusion Matrix LR\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(lr_cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Logistic Regression Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.savefig(\"../graph/confusion_lr.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Confusion Matrix RF\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(rf_cm, annot=True, fmt=\"d\", cmap=\"Greens\")\n",
    "plt.title(\"Random Forest Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.savefig(\"../graph/confusion_rf.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Done\n",
    "print(\"\\nAll figures saved in the /graph folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cc18f9-9fca-4188-935a-8dc02a4eb274",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
